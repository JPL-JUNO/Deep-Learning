"""
@Title: è®­ç»ƒè¯æ€§æ ‡æ³¨å™¨
@Author(s): Stephen CUI
@LastEditor(s): Stephen CUI
@CreatedTime: 2023-08-22 19:31:50
@Description: ä½¿ç”¨ NLTK çš„æ ‡æ³¨é›†è¯­æ–™åº“å’Œ sklearn éšæœºæ£®æ—æœºå™¨å­¦ä¹ æ¨¡å‹æ¥è®­ç»ƒè‡ªå·±çš„è¯æ€§æ ‡æ³¨å™¨
"""
# 1. æ•´ä¸ªè¿‡ç¨‹å°†æ˜¯ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦é¢„æµ‹å¥å­ä¸­ç»™å®šå•è¯çš„è¯æ€§æ ‡ç­¾
# 2. ä½¿ç”¨å¸¦æœ‰è¯æ€§æ ‡æ³¨çš„ NLTK treebank æ•°æ®é›†ä½œä¸ºè®­ç»ƒæ•°æ®æˆ–æ ‡æ³¨æ•°æ®ï¼Œå¹¶æå–å•è¯çš„å‰ç¼€ã€åç¼€ä»¥
# 3. åŠæ–‡æœ¬ä¸­çš„å‰åºå•è¯å’Œç›¸é‚»å•è¯ä½œä¸ºè®­ç»ƒçš„ç‰¹å¾

import nltk
from sklearn.feature_extraction import DictVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix


def sentence_features(st: list, idx: int) -> dict:
    """è®¡ç®—ä¸€ä¸ªä¸€ä¸ªå•è¯åœ¨ä¸€ä¸ªå¥å­ä¸­çš„ä¸€äº›ç‰¹å¾ï¼ŒåŒ…æ‹¬å‰ç¼€1ï¼Œ å‰ç¼€2ï¼Œå‰ç¼€3ï¼Œåç¼€1ï¼Œåç¼€2ï¼Œ åç¼€3ï¼Œå‰åä¸€ä¸ªå•è¯ï¼Œæ˜¯å¦æ˜¯å¤§å†™å¼€å¤´ï¼Œæ‰€åœ¨çš„ç´¢å¼•ä¸ä»åå‘å‰çš„ç´¢å¼•ã€‚

    æ¯ä¸ªå¥å­ä»¥ Python åˆ—è¡¨çš„å½¢å¼ä¸å½“å‰å•è¯çš„ç´¢å¼•ä¸€èµ·è¢«ä¼ å…¥ï¼Œä»¥æå–è¯¥å•è¯çš„ç‰¹å¾ï¼Œå…¶ä¸­ç´¢å¼• idx ç”¨äºè·å–ç›¸é‚»å•è¯çš„ç‰¹å¾ä»¥åŠå•è¯çš„å‰ç¼€/åç¼€ã€‚

    Parameters
    ----------
    st : list
        è¯å…ƒç»„æˆçš„å¥å­
    idx : int
        å¸¦åˆ¤æ–­çš„ç´¢å¼•

    Returns
    -------
    dict
        ç‰¹å¾å­—å…¸
    """
    d_ft = {}
    d_ft["word"] = st[idx]
    d_ft["dist_from_first"] = idx - 0
    d_ft["dist_from_last"] = len(st) - idx
    # åˆ¤æ–­æ˜¯ä¸æ˜¯å¤§å†™å­—æ¯å¼€å¤´
    d_ft['capitalized'] = st[idx][0].upper() == st[idx][0]
    d_ft["prefix1"] = st[idx][0]
    d_ft["prefix2"] = st[idx][:2]
    d_ft["prefix3"] = st[idx][:3]
    d_ft["suffix1"] = st[idx][-1:]
    d_ft["suffix2"] = st[idx][-2:]
    d_ft["suffix3"] = st[idx][-3:]
    d_ft["prev_word"] = "" if idx == 0 else st[idx - 1]
    d_ft["next_word"] = "" if idx == (len(st) - 1) else st[idx + 1]
    d_ft["numeric"] = st[idx].isdigit()
    return d_ft


def get_untagged_sentence(tagged_sentence: list[tuple]) -> list[str]:
    # ğŸš©
    [s, _] = zip(*tagged_sentence)
    return list(s)


def ext_ft(tg_sent):
    sent, tag = [], []
    for tg in tg_sent:
        for index in range(len(tg)):
            sent.append(sentence_features(get_untagged_sentence(tg), index))
            tag.append(tg[index][1])
    return sent, tag


tagged_sentences = nltk.corpus.treebank.tagged_sents(tagset="universal")

X, y = ext_ft(tagged_sentences)

n_sample = 50_000
dict_vectorizer = DictVectorizer(sparse=True)
X_transformed = dict_vectorizer.fit_transform(X[:n_sample])
y_sampled = y[:n_sample]

# è¿™é‡Œæœ‰ä¸€ç‚¹çš„é—®é¢˜ï¼Œåˆ’åˆ†æ•°æ®é›†ä¹‹å‰è¿›è¡Œäº†å˜æ¢ï¼Œå®é™…ä¸Šä¼šé«˜ä¼°æ¨¡å‹çš„æ€§èƒ½
X_train, X_test, y_train, y_test = train_test_split(
    X_transformed, y_sampled, test_size=.2, random_state=123)

rf = RandomForestClassifier(n_jobs=-1)
rf.fit(X_train, y_train)


def predict_pos_tags(sentence):
    features = [sentence_features(sentence, index)
                for index in range(len(sentence))]
    features = dict_vectorizer.transform(features)
    tags = rf.predict(features)
    return zip(sentence, tags)


test_sentence = "This is a sample POS tagger"
for tagged in predict_pos_tags(test_sentence.split()):
    print(tagged)

predictions = rf.predict(X_test)
acc = accuracy_score(y_test, predictions)
print(acc)

conf_matrix = confusion_matrix(y_test, predictions)
import matplotlib.pyplot as plt
import numpy as np
plt.figure(figsize=(10, 10))
plt.xticks(np.arange(len(rf.classes_)), rf.classes_)
plt.yticks(np.arange(len(rf.classes_)), rf.classes_)
plt.imshow(conf_matrix, cmap=plt.cm.Blues)
plt.colorbar()
plt.show()

feature_list = zip(
    dict_vectorizer.get_feature_names_out(), rf.feature_importances_
)
sorted_features = sorted(feature_list, key=lambda x: x[1], reverse=True)
print(sorted_features[0:20])
# sorted_features[0:20]
