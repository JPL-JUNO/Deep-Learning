"""
@Title: è®­ç»ƒå½±è¯„æƒ…æ„Ÿåˆ†ç±»å™¨
@Author(s): Stephen CUI
@LastEditor(s): Stephen CUI
@CreatedTime: 2023-08-22 22:41:43
@Description: 
"""
from nltk.corpus import movie_reviews
import random
import nltk

# categories() å‡½æ•°å°†è¿”å› pos æˆ– negï¼Œåˆ†åˆ«ä»£è¡¨æ­£é¢æˆ–è´Ÿé¢æƒ…ç»ªã€‚
cats = movie_reviews.categories()
reviews = []
for cat in cats:
    for fid in movie_reviews.fileids(cat):
        review = (list(movie_reviews.words(fid)), cat)
        reviews.append(review)
random.shuffle(reviews)

all_word_in_reviews = nltk.FreqDist(wd.lower() for wd in movie_reviews.words())
top_word_in_reviews = [list(wds) for wds in zip(
    *all_word_in_reviews.most_common(2_000))][0]


def ext_ft(review, top_words):
    # æ¯æ¡ç”µå½±è¯„è®ºéƒ½å°†è¢«ä¼ é€’ç»™ ext_ft()å‡½æ•°å¹¶ç”±è¯¥å‡½æ•°è¿”å›åŒ…å«äºŒè¿›åˆ¶ç‰¹å¾çš„å­—å…¸
    review_wds = set(review)
    ft = {}
    for wd in top_words:
        ft["word_present({})".format(wd)] = (wd in review_wds)
    return ft


feature_sets = [(ext_ft(d, top_word_in_reviews), c) for (d, c) in reviews]
train_set, test_set = feature_sets[200:], feature_sets[:200]

# ğŸ€
classifier = nltk.NaiveBayesClassifier.train(train_set)
print(nltk.classify.accuracy(classifier, test_set))

classifier.show_most_informative_features(10)

# ä¸‹é¢ä½¿ç”¨ sklearn ä¸­çš„éšæœºæ£®æ—æ¥è¿›è¡Œè¯„ä¼°
from sklearn.feature_extraction import DictVectorizer
d_vect = None


def get_train_test(tr_set, te_set):
    """å¯¹è®­ç»ƒæ•°æ®è½¬ä¸º 0-1 çš„ç¼–ç æ ¼å¼"""
    global d_vect
    d_vect = DictVectorizer(sparse=True)
    X_tr, y_tr = zip(*tr_set)
    X_tr = d_vect.fit_transform(X_tr)
    X_te, y_te = zip(*te_set)
    X_te = d_vect.transform(X_te)
    return X_tr, y_tr, X_te, y_te


X_train, y_train, X_test, y_test = get_train_test(train_set, test_set)
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100,
                            n_jobs=-1, random_state=10)
rf.fit(X_train, y_train)
# å¾®å°æå‡
from sklearn.metrics import accuracy_score
preds = rf.predict(X_test)
print(accuracy_score(preds, y_test))

# æˆ‘ä»¬åˆ©ç”¨ NLTK åœç”¨è¯è¯­æ–™åº“æ¥åˆ é™¤åœç”¨è¯ï¼Œå¹¶åƒä¹‹å‰ä¸€æ ·é€‰æ‹©å‰ 2000 ä¸ªæœ€ä¸ºå¸¸è§çš„å•è¯
from nltk.corpus import stopwords
stopwords_list = stopwords.words("english")
all_word_in_reviews = nltk.FreqDist(
    word.lower() for word in movie_reviews.words() if word not in stopwords_list)
top_word_in_reviews = [list(words) for words in zip(
    *all_word_in_reviews.most_common(2_000))][0]
feature_sets = [(ext_ft(d, top_word_in_reviews), c) for d, c in reviews]
train_set, test_set = feature_sets[200:], feature_sets[:200]
X_train, y_train, X_test, y_test = get_train_test(train_set, test_set)
rf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs=-1)
rf.fit(X_train, y_train)
preds = rf.predict(X_test)
# å®é™…ä¸Šï¼Œåˆ é™¤è¯¥æ•°æ®é›†çš„åœç”¨è¯å¹¶æ²¡æœ‰æé«˜æ¨¡å‹çš„è¡¨ç°ï¼Œåè€Œä½¿å‡†ç¡®ç‡æœ‰æ‰€é™ä½ã€‚
print(accuracy_score(preds, y_test))

feature_list = zip(d_vect.get_feature_names_out(), rf.feature_importances_)
feature_list = sorted(feature_list, key=lambda x: x[1], reverse=True)
print(feature_list[:20])
# è™½ç„¶äºŒè¿›åˆ¶ç‰¹å¾å¯èƒ½å¯¹åŸºæœ¬æ–‡æœ¬åˆ†ç±»ä»»åŠ¡å¾ˆæœ‰ç”¨ï¼Œä½†æ˜¯ä¸é€‚ç”¨äºæ›´ä¸ºå¤æ‚çš„æ–‡æœ¬åˆ†ç±»åº”ç”¨ã€‚
# ä¸»è¦åœ¨äºç»´åº¦å¤ªå¤§ï¼Œæƒé‡çš„è®¡ç®—ä¸éœ€è¦æ¶‰åŠè¿™ä¹ˆå¤šçš„è®¡ç®—
