\chapter{自然语言和单词的分布式表示\label{Ch02}}
\section{同义词词典}
回顾自然语言处理的历史，人们已经尝试过很多次类似这样的人工定义单词含义的活动。但是，目前被广泛使用的并不是《新华字典》那样的常规词典，而是一种被称为同义词词典（thesaurus）的词典。在同义词词典中，具有相同含义的单词（同义词）或含义类似的单词（近义词）被归类到同一个组中。比如，使用，我们可以知道 car 的同义词有 automobile、motorcar 等
\subsection{WordNet}
在自然语言处理领域，最著名的同义词词典是 WordNet。使用 WordNet，可以获得单词的近义词，或者利用单词网络。使用单词网络，可以计算单词之间的相似度。
\subsection{同义词词典的问题}
\begin{itemize}
    \item 难以顺应时代变化
    \item 人力成本高
    \item 无法表示单词的微妙差异
\end{itemize}
\section{基于计数的方法}
从介绍基于计数的方法开始，我们将使用语料库（corpus）。简而言之，语料库就是大量的文本数据。不过，语料库并不是胡乱收集数据，一般收集的都是用于自然语言处理研究和应用的文本数据。

\begin{tcolorbox}
    自然语言处理领域中使用的语料库有时会给文本数据添加额外的信息。比如，可以给文本数据的各个单词标记词性。在这种情况下，为了方便计算机处理，语料库通常会被结构化（比如，采用树结构等数据形式）。这里，假定我们使用的语料库没有添加标签，而是作为一个大的文本文件，只包含简单的文本数据。
\end{tcolorbox}

能不能将类似于颜色的向量表示方法运用到单词上呢？更准确地说，可否在单词领域构建紧凑合理的向量表示呢？接下来，我们将关注能准确把握单词含义的向量表示。在自然语言处理领域，这称为分布式表示。

单词的分布式表示将单词表示为固定长度的向量。这种向量的特征在于它是用密集向量表示的。密集向量的意思是，向量的各个元素（大多数）是由非0实数表示的。例如，三维分布式表示是 $[0.21,-0.45,0.83]$。
\subsection{分布式假设}
“某个单词的含义由它周围的单词形成”，称为分布式假设（distributional hypothesis）。分布式假设所表达的理念非常简单。单词本身没有含义，单词含义由它所在的上下文（语境）形成。上下文是指某个居中单词的周围词汇。这里，我们将上下文的大小（即周围的单词有多少个）称为\textbf{窗口大小}（window size）。窗口大小为 1，上下文包含左右各 1 个单词；窗口大小为 2，上下文包含左右各 2 个单词，以此类推。
\subsection{共现矩阵}
\figures{fig2-7}{用表格汇总各个单词的上下文中包含的单词的频数}

\subsection{向量间的相似度}
测量向量间的相似度有很多方法，其中具有代表性的方法有向量内积或欧式距离等。虽然除此之外还有很多方法，但是在测量单词的向量表示的相似度方面，\textbf{余弦相似度}（cosine similarity）是很常用的。设有 $\bm{x} = (x_1, x_2, x_3,\cdots , x_n)$ 和 $\bm{y} = (y_1, y_2, y_3,\cdots, y_n)$ 两个向量，它们之间的余弦相似度的定义如下式所示：
\begin{equation}
    similarity(\bm{x},\bm{y})=\frac{x_1y_1+\cdots+x_ny_n}{\sqrt{x_1^2+\cdots+x_n^2}\sqrt{y_1^2+\cdots+y_n^2}}
\end{equation}

余弦相似度直观地表示了“两个向量在多大程度上指向同一方向”。两个向量完全指向相同的方向时，余弦相似度为 1；完全指向相反的方向时，余弦相似度为 -1。