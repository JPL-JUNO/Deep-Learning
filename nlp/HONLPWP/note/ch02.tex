\chapter{使用 NLTK 进行文本分类和词性标注\label{ch02}}

自然语言工具包（Natural Language Toolkit，NLTK）是一个用于 NLP 任务的 Python 库，其功能涉及分词、分句、执行进阶任务（如语法分析和文本分类），等等。NLTK 提供了一些针对自然语言的模块和接口，可用于执行诸如文档主题识别、词性标注、情感分析等任务。为了实验各种 NLP 任务，NLTK 还提供了各种文本语料库的模块，从基本的文本集合到带标签的结构化文本（如 WordNet）。
\section{文本预处理及探索性分析}
文本预处理步骤涉及如分词、词干提取和去除停用词之类的任务。对准备好的文本数据进行探索性分析可以了解其主要特征，包括文本的主题和词频分布。
\subsection{分词}
单词词元（token）是任何 NLP 任务都会涉及的文本基本单元。处理文本时，第一步就是将文本拆分为词元。NLTK 为此提供了不同类型的分词器。

为实现基于标点和空格的文本分割，NLTK 也提供了能同时标注出标点符号的 \verb|wordpunct_tokenize| 分词器。

我们也可以使用 NLTK 的正则表达式分词器实现自定义分词。
\subsection{词干提取}
词干提取是一种文本预处理任务，将单词的相关或相似变体（例如 walking）转换为其基本形式（例如 walk），因为它们具有相同的含义。词干提取转换的基本操作之一是将单词的复数形式还原为单数形式，例如将 apples 还原为 apple。尽管这是一个非常简单的转换，但确实存在更加复杂的操作。
\subsection{去除停用词}